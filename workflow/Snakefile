import pandas as pd
import os
from snakemake.utils import validate


#configfile: "config/config.yml"


validate(config, "schemas/config.schema.yml")


include: "scripts/common.py"


localrules:
    parse_results,
    multiqc,
    parse_sintax,
    map_qc,
    samtools_stats,
    krona,
    all,


# Read sample list
sample_df = pd.read_csv(config["sample_list"], index_col=0)
samples = sample_df.to_dict(orient="index")

# Read mapping list
mapping_df = pd.read_csv(config["mappings_list"], index_col=0)
mappings = mapping_df.to_dict(orient="index")


rule all:
    """Workflow pseudo rule"""
    input:
        all_output,


rule gzip:
    output:
        "{f}.fastq.gz",
    input:
        "{f}.fastq",
    log:
        "{f}.gzip.log",
    container:
        "docker://snakemake/snakemake:latest"
    shell:
        """
        gzip -c {input} > {output} 2>{log}
        """


rule fastp:
    output:
        R1=temp("{out_folder}/results/fastp/{sample}.fastp.R1.fastq.gz"),
        R2=temp("{out_folder}/results/fastp/{sample}.fastp.R2.fastq.gz"),
    log:
        log="{out_folder}/logs/fastp/{sample}.fastp.log",
        json="{out_folder}/logs/fastp/{sample}.fastp.json",
    input:
        R1=lambda wildcards: sorted(
            [x for x in samples[wildcards.sample]["fwd_libs"].split(";")]
        ),
        R2=lambda wildcards: sorted(
            [x for x in samples[wildcards.sample]["rev_libs"].split(";")]
        ),
    envmodules:
        "bioinfo-tools",
        "fastp/0.23.2",
    conda:
        "envs/fastp.yml"
    group:
        "group1"
    resources:
        runtime=60 * 10,
    threads: 8
    params:
        tmpR1="$TMPDIR/{sample}.R1.fastq.gz",
        tmpR2="$TMPDIR/{sample}.R2.fastq.gz",
        outR1="$TMPDIR/{sample}.fastp.R1.fastq.gz",
        outR2="$TMPDIR/{sample}.fastp.R2.fastq.gz",
        complexity_threshold=config["fastp"]["complexity_threshold"],
    shell:
        """
        cat {input.R1} > {params.tmpR1}
        cat {input.R2} > {params.tmpR2}
        fastp --thread {threads} -y -Y {params.complexity_threshold} \
            -i {params.tmpR1} -I {params.tmpR2} -o {params.outR1} \
            -O {params.outR2} -j {log.json} > {log.log} 2>&1
        mv {params.outR1} {output.R1}
        mv {params.outR2} {output.R2}
        rm {params.tmpR1} {params.tmpR2}
        """


rule multiqc:
    output:
        "{out_folder}/results/multiqc/multiqc.html",
        directory("{out_folder}/results/multiqc/multiqc_data"),
    log:
        "{out_folder}/logs/multiqc/multiqc.log",
    input:
        fastp=expand(
            "{{out_folder}}/logs/fastp/{sample}.fastp.json", sample=samples.keys()
        ),
    conda:
        "envs/multiqc.yml"
    envmodules:
        "bioinfo-tools",
        "MultiQC/1.12",
    params:
        tmpdir="$TMPDIR/biodivcao_multiqc",
        outdir=lambda wildcards, output: os.path.dirname(output[0]),
    shell:
        """
        mkdir -p {params.tmpdir}
        cp {input} {params.tmpdir}
        multiqc -f -o {params.outdir} -n multiqc.html {params.tmpdir} > {log} 2>&1
        rm -rf {params.tmpdir}
        """

## GENOME MAPPING ##
# Map CAO samples to the database of fish genomes. It first maps the reads,
# filters the results then blasts the mapped reads against nt. The mapping and
# blast results are filtered using taxon lineage info and a custom python script.
# Only reads that have a blast hit to a rayfinned fish (actinopterygii) or
# cartilagenous fish (chondrichthyes) are reported. Note that reads from a pair
# are considered as 1 in the final results.

# The pipeline requires the 'taxon_table.csv' to run. This file is produce when
# running the database build pipeline and contains the taxon info for each
# assembly contig.

rule bowtie2_index_genome:
    output:
        expand(
            "resources/genome_index/{{ref}}/{{ref}}.{suff}.bt2l",
            suff=["1", "2", "3", "4", "rev.1", "rev.2"],
        ),
    input:
        fasta=lambda wildcards: config["mappings"]["genomes"][wildcards.ref]["fasta"],
    log:
        "resources/logs/genome_mappings/{ref}/bowtie2/index.log",
    envmodules:
        "bioinfo-tools",
        "bowtie2/2.4.5",
    conda:
        "envs/mapping.yml"
    container: "https://depot.galaxyproject.org/singularity/bowtie2:2.4.5--py39hd2f7db1_3"
    threads: 20
    resources:
        runtime=lambda wildcards: 48 * 60,
        mem_mb=250000,
    params:
        tmpdir="$TMPDIR/{ref}.bowtie2",
        outdir=lambda wildcards, output: os.path.dirname(output[0]),
    shell:
        """
        mkdir -p {params.tmpdir}
        cp {input} {params.tmpdir}/{wildcards.ref}

        bowtie2-build --seed 42 --large-index {params.tmpdir}/{wildcards.ref} {params.tmpdir}/{wildcards.ref} >{log} 2>&1

        mv {params.tmpdir}/*.bt2l {params.outdir}
        rm -r {params.tmpdir}
        """


rule bowtie2_map_genome:
    output:
        bam=temp("{out_folder}/results/genome_mappings/{ref}/bowtie2/{sample}/{sample}.bam"),
    input:
        idx=rules.bowtie2_index_genome.output,
        R1=rules.fastp.output.R1,
        R2=rules.fastp.output.R2,
    log:
        log="{out_folder}/logs/genome_mappings/{ref}/bowtie2/{sample}/run.log",
        maplog="{out_folder}/logs/genome_mappings/{ref}/bowtie2/{sample}/{sample}.log",
    params:
        idx=lambda wildcards, input: os.path.splitext(input.idx[0])[0].replace(".1", ""),
        tmpdir="$TMPDIR/{ref}.{sample}.bowtie2",
    conda:
        "envs/mapping.yml"
    envmodules:
        "bioinfo-tools",
        "bowtie2/2.4.5",
        "samtools/1.9"
    resources:
        runtime = 24 * 60
    container: "https://depot.galaxyproject.org/singularity/bowtie2:2.4.5--py39hd2f7db1_3"
    threads: config["bowtie2"]["threads"]
    shell:
        """
        exec &>{log.log}
        mkdir -p {params.tmpdir}
        bowtie2 --seed 42 -p {threads} -x {params.idx} --very-sensitive -1 {input.R1} -2 {input.R2} 2> {log.maplog} \
            | samtools view -b - | samtools sort -o {params.tmpdir}/tmp.bam
        mv {params.tmpdir}/tmp.bam {output.bam}
        rm -rf {params.tmpdir}
        """


# Filter bamfile. The temporary sam file is used for parsing the results.
rule filter_bam:
    input:
        rules.bowtie2_map_genome.output.bam
    output:
        bam="{out_folder}/results/genome_mappings/{ref}/bowtie2/{sample}/{sample}.filtered.bam",
        sam=temp("{out_folder}/results/genome_mappings/{ref}/bowtie2/{sample}/{sample}.filtered.sam")
    log:
        "{out_folder}/logs/genome_mappings/{ref}/bowtie2/{sample}/filter_bam.log"
    conda:
        "envs/mapping.yml"
    params:
        tmpdir="$TMPDIR/{ref}.{sample}",
    resources:
        runtime = 2 * 60
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        samtools view -b -h -q 40 -f 0x2 -o {params.tmpdir}/tmp.bam {input[0]}
        samtools view -h -q 40 -f 0x2 -o {params.tmpdir}/tmp.sam {input[0]}
        mv {params.tmpdir}/tmp.bam {output.bam}
        mv {params.tmpdir}/tmp.sam {output.sam}
        rm -rf {params.tmpdir}
        """

# Get mapped reads:
rule get_reads:
    input:
        rules.filter_bam.output.bam
    output:
        "{out_folder}/results/genome_mappings/{ref}/bowtie2/{sample}/{sample}.reads.fa"
    conda:
        "envs/mapping.yml"
    resources:
        runtime = 30
    shell:
        """
        samtools fasta -n -o {output[0]} {input[0]}
        """

# Blast reads against nt
rule blast_reads:
    input:
        rules.get_reads.output[0]
    output:
        "{out_folder}/results/genome_mappings/{ref}/bowtie2/{sample}/blast_outs/{sample}.result.txt"
    log:
        "{out_folder}/logs/blast_reads/{ref}/{sample}.log"
    params:
        db=config["blast"]["db"],
        evalue=config["blast"]["evalue"],
        max_target=config["blast"]["max_target_seqs"]
    threads: 10
    envmodules:
        "bioinfo-tools",
        "blast/2.9.0+",
        "blast_databases"
    conda:
        "envs/blast.yml"
    resources:
        runtime = 24 * 60
    shell:
        """
        blastn -num_threads {threads} -query {input[0]} \
        -db {params.db} -evalue {params.evalue} -max_target_seqs {params.max_target} -outfmt \
        "6 qseqid sseqid pident length mismatch gapopen \
        qstart qend sstart send evalue bitscore staxid salltitles" \
        -out {output[0]} >{log} 2>&1
        """

# Filter mapping result using blast results and
# taxon lineage info. Report counts per species
# and counts per taxon for each sample.

rule parse_results:
    input:
        reads=rules.blast_reads.output[0],
        sam=rules.filter_bam.output.sam,
        tax=lambda wildcards: config["mappings"]["genomes"][wildcards.ref]["taxon_table"]
    output:
        "{out_folder}/results/genome_mappings/{ref}/counts/{sample}_taxid_counts.txt",
        "{out_folder}/results/genome_mappings/{ref}/counts/{sample}_species_counts.txt",
    log:
        "{out_folder}/logs/blast_reads/{ref}/{sample}.parse_results.log"
    conda:
        "envs/ete3.yml"
    shell:
        """
        python3 workflow/scripts/filter_aln_and_blast_results.py {input.reads} {input.sam} {input.tax} {output[0]} {output[1]} 2>{log}
        """



rule bwa_index:
    output:
        idx=expand(
            "{{out_folder}}/resources/{{map_name}}/bwa-mem2/index.{suff}",
            suff=["0123", "amb", "ann", "pac", "bwt.2bit.64"],
        ),
    input:
        ref=lambda wildcards: mappings[wildcards.map_name]["reference"],
    log:
        "{out_folder}/logs/mappings/{map_name}/bwa-mem2/index.log",
    params:
        tmpdir="$TMPDIR/{map_name}.bwa-mem2",
        outdir=lambda wildcards, output: os.path.dirname(output[0]),
    conda:
        "envs/mapping.yml"
    envmodules:
        "bioinfo-tools",
        "bwa-mem2/2.2.1-20211213-edc703f",
    resources:
        runtime=60 * 10,
    threads: 10
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        bwa-mem2 index -p {params.tmpdir}/index {input.ref}
        mv {params.tmpdir}/index* {params.outdir}
        rm -rf {params.tmpdir}
        """


rule bwa_mem2:
    output:
        bam="{out_folder}/results/mappings/{map_name}/bwa-mem2/{sample}.filtered.bam",
    input:
        R1=rules.fastp.output.R1,
        R2=rules.fastp.output.R2,
        idx=rules.bwa_index.output.idx,
    log:
        log="{out_folder}/logs/mappings/{map_name}/bwa-mem2/{sample}/run.log",
        maplog="{out_folder}/logs/mappings/{map_name}/bwa-mem2/{sample}/{sample}.log",
        coverm="{out_folder}/logs/mappings/{map_name}/bwa-mem2/{sample}/coverm.log",
        env="{out_folder}/logs/mappings/{map_name}/bwa-mem2/{sample}/run_env.yaml",
    params:
        tmpdir="$TMPDIR/{map_name}.bwa-mem2.{sample}",
        ani_cutoff=lambda wildcards: mappings[wildcards.map_name]["ani_cutoff"],
        min_len=lambda wildcards: mappings[wildcards.map_name]["min_len"],
        idx=lambda wildcards, input: os.path.splitext(input.idx[0])[0],
    conda:
        "envs/mapping.yml"
    threads: config["bwa-mem2"]["threads"]
    resources:
        runtime=60 * 24,
    shell:
        """
        exec &>{log.log}
        mkdir -p {params.tmpdir}
        bwa-mem2 mem -t {threads} {params.idx} {input.R1} {input.R2} 2>{log.maplog} \
            | samtools view -b - | samtools sort -o {params.tmpdir}/mapping_pairs.bam

        coverm filter -b {params.tmpdir}/mapping_pairs.bam -o {params.tmpdir}/mapping_filtered.bam --min-read-percent-identity {params.ani_cutoff} --min-read-aligned-length {params.min_len} --threads {threads} > {log.coverm} 2>&1
        mv {params.tmpdir}/mapping_filtered.bam {output.bam}
        rm -rf {params.tmpdir}
        conda env export > {log.env}
        """


rule bowtie2_index:
    output:
        idx=expand(
            "{{out_folder}}/resources/{{map_name}}/bowtie2/index.{suff}.bt2l",
            suff=range(1, 5),
        ),
    input:
        ref=lambda wildcards: mappings[wildcards.map_name]["reference"],
    log:
        "{out_folder}/logs/mappings/{map_name}/bowtie2/index.log",
    params:
        tmpdir="$TMPDIR/{map_name}.bowtie2",
        outdir=lambda wildcards, output: os.path.dirname(output[0]),
    conda:
        "envs/mapping.yml"
    resources:
        runtime=60 * 10,
    threads: 4
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        bowtie2-build --seed 42 --large-index --threads {threads} {input.ref} {params.tmpdir}/index
        mv {params.tmpdir}/index* {params.outdir}
        rm -rf {params.tmpdir}
        """


rule bowtie2:
    output:
        bam="{out_folder}/results/mappings/{map_name}/bowtie2/{sample}.filtered.bam",
    input:
        R1=rules.fastp.output.R1,
        R2=rules.fastp.output.R2,
        idx=rules.bowtie2_index.output.idx,
    log:
        log="{out_folder}/logs/mappings/{map_name}/bowtie2/{sample}/run.log",
        maplog="{out_folder}/logs/mappings/{map_name}/bowtie2/{sample}/{sample}.log",
        coverm="{out_folder}/logs/mappings/{map_name}/bowtie2/{sample}/coverm.log",
        env="{out_folder}/logs/mappings/{map_name}/bowtie2/{sample}/run_env.yaml",
    params:
        tmpdir="$TMPDIR/{map_name}.bowtie2.{sample}",
        ani_cutoff=lambda wildcards: mappings[wildcards.map_name]["ani_cutoff"],
        min_len=lambda wildcards: mappings[wildcards.map_name]["min_len"],
        idx=lambda wildcards, input: os.path.splitext(input.idx[0])[0].replace(".1", ""),
    conda:
        "envs/mapping.yml"
    threads: config["bowtie2"]["threads"]
    resources:
        runtime=60 * 24,
    shell:
        """
        exec &>{log.log}
        mkdir -p {params.tmpdir}
        bowtie2 --seed 42 -p {threads} -x {params.idx} --very-sensitive -1 {input.R1} -2 {input.R2} 2>{log.maplog} \
            | samtools view -b - | samtools sort -o {params.tmpdir}/mapping_pairs.bam

        coverm filter -b {params.tmpdir}/mapping_pairs.bam -o {params.tmpdir}/mapping_filtered.bam --min-read-percent-identity {params.ani_cutoff} --min-read-aligned-length {params.min_len} --threads {threads} > {log.coverm} 2>&1
        mv {params.tmpdir}/mapping_filtered.bam {output.bam}
        rm -rf {params.tmpdir}
        conda env export > {log.env}
        """


rule minimap2_index:
    output:
        idx="{out_folder}/resources/{map_name}/minimap2/index",
    input:
        ref=lambda wildcards: mappings[wildcards.map_name]["reference"],
    log:
        "{out_folder}/logs/mappings/{map_name}/minimap2/index.log",
    threads: config["minimap2"]["threads"]
    params:
        split_num=config["minimap2"]["split_num"],
        tmpdir="$TMPDIR/{map_name}.minimap2",
        outdir=lambda wildcards, output: os.path.dirname(output.idx),
    conda:
        "envs/mapping.yml"
    envmodules:
        "bioinfo-tools",
        "minimap2/2.24-r1122",
    resources:
        runtime=60 * 24,
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        minimap2 -I {params.split_num}G -t {threads} -d {params.tmpdir}/index {input.ref}
        mv {params.tmpdir}/* {params.outdir}
        rm -rf {params.tmpdir}        
        """


rule minimap2:
    output:
        bam="{out_folder}/results/mappings/{map_name}/minimap2/{sample}.filtered.bam",
    input:
        R1=rules.fastp.output.R1,
        R2=rules.fastp.output.R2,
        idx=rules.minimap2_index.output.idx,
    log:
        log="{out_folder}/logs/mappings/{map_name}/minimap2/{sample}/run.log",
        maplog="{out_folder}/logs/mappings/{map_name}/minimap2/{sample}/{sample}.log",
        coverm="{out_folder}/logs/mappings/{map_name}/minimap2/{sample}/coverm.log",
        env="{out_folder}/logs/mappings/{map_name}/minimap2/{sample}/run_env.yaml",
    params:
        tmpdir="$TMPDIR/{map_name}.minimap2.{sample}",
        ani_cutoff=config["min_ani_cutoff"],
        min_len=config["min_align_len"],
    conda:
        "envs/mapping.yml"
    envmodules:
        "bioinfo-tools",
        "minimap2/2.24-r1122",
    threads: config["minimap2"]["threads"]
    resources:
        runtime=60 * 24,
    #group:
    #    "group1"
    shell:
        """
        exec &>{log.log}
        mkdir -p {params.tmpdir}
        minimap2 -x sr --MD -a -t {threads} {input.idx} {input.R1} {input.R2} 2> {log.maplog} \
            | samtools view -b - | samtools sort -o {params.tmpdir}/mapping_pairs.bam

        coverm filter -b {params.tmpdir}/mapping_pairs.bam -o {params.tmpdir}/mapping_filtered.bam --min-read-percent-identity {params.ani_cutoff} --min-read-aligned-length {params.min_len} --threads {threads} > {log.coverm} 2>&1
        mv {params.tmpdir}/mapping_filtered.bam {output.bam}
        rm -rf {params.tmpdir}
        conda env export > {log.env}
        """


rule samtools_stats:
    output:
        stats="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.stats",
    input:
        "{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.filtered.bam",
    log:
        "{out_folder}/logs/mappings/{map_name}/{mapper}/{sample}.filtered.samtools.stats",
    params:
        tmp="$TMPDIR/{map_name}.{mapper}.{sample}.stats",
    conda:
        "envs/mapping.yml"
    shell:
        """
        exec &>{log}
        samtools stats {input} > {params.tmp}
        mv {params.tmp} {output.stats}
        """


rule map_qc:
    output:
        "{out_folder}/results/mappings/{map_name}/map_qc.html",
    input:
        expand(
            "{{out_folder}}/results/mappings/{{map_name}}/{mapper}/{sample}.stats",
            mapper=config["mappers"],
            sample=samples.keys(),
        ),
    log:
        "{out_folder}/logs/multiqc/map_qc/{map_name}.log",
    conda:
        "envs/multiqc.yml"
    params:
        input=lambda wildcards, input: "\n".join(input),
        tmpdir="$TMPDIR/{map_name}.map_qc",
        outdir=lambda wildcards, output: os.path.dirname(output[0]),
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        echo "{params.input}" > {params.tmpdir}/files
        multiqc -f -o {params.outdir} -dd 1 -n map_qc -l {params.tmpdir}/files
        rm -rf {params.tmpdir}
        """


rule extract_reads:
    output:
        fwd="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}_fwd.fastq.gz",
        rev="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}_rev.fastq.gz",
        unp="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}_unp.fastq.gz",
    input:
        bam="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.filtered.bam",
    log:
        "{out_folder}/logs/mappings/{map_name}/{mapper}/{sample}.extract_reads.log",
    params:
        tmpdir="$TMPDIR/{map_name}.{mapper}.{sample}",
        tmp_bam="$TMPDIR/{map_name}.{mapper}.{sample}/namesorted.bam",
        outdir=lambda wildcards, output: os.path.dirname(output.fwd),
        ani_cutoff=lambda wildcards: mappings[wildcards.map_name]["ani_cutoff"],
        min_len=lambda wildcards: mappings[wildcards.map_name]["min_len"],
    conda:
        "envs/mapping.yml"
    resources:
        runtime=60 * 12,
    threads: 4
    shell:
        """
        exec &> {log}
        mkdir -p {params.tmpdir}
        coverm filter -b {input.bam} -o {params.tmpdir}/mapping_filtered.bam --min-read-percent-identity {params.ani_cutoff} --min-read-aligned-length {params.min_len} --threads {threads}
        samtools sort -n {params.tmpdir}/mapping_filtered.bam > {params.tmp_bam}
        samtools fastq -@ {threads} {params.tmp_bam} -1 {params.tmpdir}/{wildcards.sample}_fwd.fastq -2 {params.tmpdir}/{wildcards.sample}_rev.fastq -s {params.tmpdir}/{wildcards.sample}_unp.fastq 2> {log}
        gzip {params.tmpdir}/*.fastq
        mv {params.tmpdir}/*.fastq.gz {params.outdir}
        rm -rf {params.tmpdir}
        """


rule sintax:
    output:
        "{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.sintax.tsv",
    input:
        seq=expand(
            "{{out_folder}}/results/mappings/{{map_name}}/{{mapper}}/{{sample}}_{seqtype}.fastq.gz",
            seqtype=["fwd", "rev", "unp"],
        ),
        db=config["sintax"]["db"],
    log:
        "{out_folder}/logs/mappings/{map_name}/{mapper}/{sample}.sintax.log",
    params:
        fastq="$TMPDIR/{map_name}.{mapper}.{sample}/reads.fastq.gz",
        tmpdir="$TMPDIR/{map_name}.{mapper}.{sample}",
        cutoff=config["sintax"]["cutoff"],
        out="$TMPDIR/{map_name}.{mapper}.{sample}/{sample}.sintax.tsv",
    conda:
        "envs/sintax.yml"
    resources:
        runtime=60 * 10,
        mem_mb=12000,
    threads: 2
    shell:
        """
        exec &>{log}
        mkdir -p {params.tmpdir}
        cat {input.seq} > {params.fastq}
        vsearch --sintax {params.fastq} --db {input.db} --randseed 15 --sintax_cutoff {params.cutoff} --tabbedout {params.out} --threads 1 --strand both > {log} 2>&1
        mv {params.out} {output}
        rm -rf {params.tmpdir}
        """


rule parse_sintax:
    output:
        tsv="{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.sintax.parsed.tsv",
        krona=temp(
            "{out_folder}/results/mappings/{map_name}/{mapper}/{sample}.sintax.parsed.krona.txt"
        ),
    input:
        rules.sintax.output,
    log:
        "{out_folder}/logs/mappings/{map_name}/{mapper}/{sample}.parse_sintax.log",
    params:
        src="workflow/scripts/parse_sintax.py",
        cutoff=config["sintax"]["cutoff"],
    container:
        "docker://snakemake/snakemake:latest"
    shell:
        """
        python {params.src} -c {params.cutoff} -k {output.krona} {input} > {output.tsv} 2>{log}
        """


rule krona:
    output:
        "{out_folder}/results/mappings/{map_name}/{mapper}/krona/krona.html",
    input:
        expand(
            "{{out_folder}}/results/mappings/{{map_name}}/{{mapper}}/{sample}.sintax.parsed.krona.txt",
            sample=samples.keys(),
        ),
    log:
        "{out_folder}/logs/mappings/{map_name}/{mapper}/krona.log",
    conda:
        "envs/krona.yml"
    params:
        input_string=krona_input_string,
    shell:
        """
        ktImportText -o {output} {params.input_string} > {log} 2>&1
        """
